# ğŸ§  Brain-Llama3-Encoding: A Preliminary Replication
## æ¢ç´¢ LLaMA-3.1 ä¸äººè„‘çš„è¯­ä¹‰å…±é¸£ï¼šåŸºäº fMRI çš„ç¼–ç æ¨¡å‹å¤ç°

> **Project Status:** ğŸš§ Preliminary Release (High-intensity Sprint)
> **Base Paper:** Gao et al. (2025) [cite_start]- *Increasing alignment of large language models with language processing in the human brain* [cite: 1, 4]

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäº **è®¡ç®—ç¥ç»è¯­è¨€å­¦ (Computational Neurolinguistics)** çš„å®è¯ç ”ç©¶ã€‚å— Gao et al. (2025) å‘è¡¨åœ¨ *Nature Computational Science* ä¸Šçš„æœ€æ–°å·¥ä½œå¯å‘ï¼Œæˆ‘åœ¨ 48 å°æ—¶å†…åŸºäº **Meta-LLaMA-3.1-8B** æ„å»ºå¹¶éªŒè¯äº†ä¸€å¥—ç®€åŒ–çš„ç¥ç»ç¼–ç  (Neural Encoding) ç®¡çº¿ã€‚

[cite_start]æœ¬é¡¹ç›®çš„æ ¸å¿ƒç›®æ ‡æ˜¯åœ¨æœ‰é™ç®—åŠ›ä¸‹ï¼ŒéªŒè¯ **æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)** æ˜¯å¦æ”¹å˜äº†å¤§è¯­è¨€æ¨¡å‹åº•å±‚çš„è¯­ä¹‰è¡¨å¾åŠå…¶ä¸äººè„‘è¯­è¨€ç½‘ç»œçš„å¯¹é½åº¦ [cite: 10, 12]ã€‚

---

## 1. æ ¸å¿ƒå‘ç° (Key Findings)

[cite_start]é€šè¿‡å¯¹æ¯” **LLaMA-3.1-Base** ä¸ **LLaMA-3.1-Instruct** åœ¨ **Le Petit Prince (LPP)** fMRI æ•°æ®é›†ä¸Šçš„ç¼–ç æ€§èƒ½ [cite: 625]ï¼Œæˆ‘ä»¬å¾—å‡ºäº†ä»¥ä¸‹åˆæ­¥ç»“è®ºï¼š

### ğŸ“ˆ 1.1 ä¸­é—´å±‚æ•ˆåº” (The "Inverted-U" Trend)
æˆ‘ä»¬æˆåŠŸå¤ç°äº†ç¥ç»è¯­è¨€å­¦é¢†åŸŸçš„ç»å…¸å‘ç°ï¼šæ¨¡å‹å¯¹å¤§è„‘çš„é¢„æµ‹èƒ½åŠ›å‘ˆç°â€œå€’Uå‹â€åˆ†å¸ƒã€‚
* **Layer 0 (Embedding):** åœ¨å»é™¤äº†å¥å­é•¿åº¦æ··æ·†åï¼Œå…¶é¢„æµ‹èƒ½åŠ›æ˜¾è‘—ä½äºä¸­é—´å±‚ã€‚
* **Middle Layers (L16-L24):** **é¢„æµ‹èƒ½åŠ›è¾¾åˆ°å³°å€¼** (Max Pearson's $r \approx 0.60$, Top-5% $\approx 0.30$)ã€‚è¿™è¡¨æ˜ LLaMA çš„ä¸­é—´å±‚è¡¨å¾æœ€æ¥è¿‘äººç±»å¤§è„‘è¿›è¡Œå¥æ³•åˆ†æå’Œè¯­ä¹‰æ•´åˆçš„åŒºåŸŸã€‚
* **Late Layers:** éšç€æ¨¡å‹ä¸“æ³¨äº Next-token Predictionï¼Œå…¶ä¸å¤§è„‘é€šç”¨ç†è§£æœºåˆ¶çš„å¯¹é½åº¦ç•¥æœ‰ä¸‹é™ã€‚

![Layer Trend](plot_B_heatmap.png)
*(å›¾ï¼šBase æ¨¡å‹åœ¨ä¸åŒ Run ä¸Šçš„å±‚çº§æ€§èƒ½çƒ­åŠ›å›¾ï¼Œæ˜¾ç¤ºä¸­é—´å±‚çš„é«˜å“åº”åŒº)*

### ğŸ”„ 1.2 å¾®è°ƒçš„â€œé›¶å½±å“â€ (Impact of Instruction Tuning)
å®éªŒæ˜¾ç¤ºï¼ŒBase å’Œ Instruct ç‰ˆæœ¬çš„å±‚çº§å¯¹é½æ›²çº¿ **é«˜åº¦é‡å  (Highly Overlapped)**ã€‚
* è¿™éªŒè¯äº† Gao et al. (2025) [cite_start]çš„ç»“è®ºï¼šæŒ‡ä»¤å¾®è°ƒ (RLHF/SFT) è™½ç„¶æå‡äº†ä»»åŠ¡è¡¨ç°ï¼Œä½†å¹¶æ²¡æœ‰æ˜¾è‘—å¢å¼ºï¼ˆç”šè‡³æœ‰æ—¶ç•¥å¾®é™ä½ï¼‰æ¨¡å‹ä¸äººç±»å¤§è„‘æ´»åŠ¨çš„å¯¹é½ç¨‹åº¦ [cite: 12, 93, 361]ã€‚
* å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¤§å¤šæ•°å±‚çº§çš„ç‚¹è½åœ¨ $y=x$ çº¿é™„è¿‘ï¼Œè¡¨æ˜ä¸¤è€…åº•å±‚è¯­ä¹‰è¡¨å¾æœºåˆ¶åŸºæœ¬ä¸€è‡´ã€‚

![Scatter Comparison](plot_C_scatter.png)

---

## 2. å®éªŒæ–¹æ³• (Methodology)

### 2.1 æ•°æ®ä¸ç¯å¢ƒ
* [cite_start]**Dataset:** *Le Petit Prince* (LPP) fMRI Dataset (Sub-EN057, ~1.5h Audio) [cite: 97, 382]ã€‚
* **Hardware:** AutoDL Cloud Server / **NVIDIA RTX 4090 (24GB VRAM)**.
* **Model Loading:** LLaMA-3.1-8B (BF16 / 4-bit Quantization via `bitsandbytes`).

### 2.2 æ ¸å¿ƒç®¡çº¿ (Pipeline)
1.  **ç‰¹å¾æå– (Feature Extraction):** æå– Layer 0-32 çš„ Hidden Statesï¼Œé‡‡ç”¨ **Sentence-level Mean Pooling** ä»¥é€‚åº”å¬åŠ›ä»»åŠ¡çš„ä½ä¿¡å™ªæ¯”ã€‚
2.  **è¡€æµåŠ¨åŠ›å­¦å»ºæ¨¡ (HRF Alignment):** ä½¿ç”¨ `nilearn` è¿›è¡Œ HRF å·ç§¯ï¼Œå¹¶åœ¨ 4s-10s èŒƒå›´å†…æœç´¢æœ€ä½³å»¶è¿Ÿ (Best Delay)ã€‚
3.  [cite_start]**é™ç»´ä¸å›å½’ (Encoding):** ä½¿ç”¨ PCA (n=15) é™ç»´ï¼Œé…åˆ Ridge Regression (5-Fold CV) è¿›è¡Œä½“ç´ çº§é¢„æµ‹ [cite: 461, 465]ã€‚

---

## 3. æŒ‘æˆ˜ä¸æ–¹æ³•è®ºæ¼”è¿› (Dev Log: Challenges & Evolution)

æœ¬é¡¹ç›®çš„å¤ç°å¹¶éä¸€å¸†é£é¡ºã€‚ä¸ºäº†é€¼è¿‘åŸè®ºæ–‡çš„é€»è¾‘ï¼Œæˆ‘ä»¬åœ¨ 48 å°æ—¶å†…ç»å†äº†ä¸‰æ¬¡å…³é”®çš„æ–¹æ³•è®ºè¿­ä»£ã€‚è¿™ä¸€è¿‡ç¨‹æ­ç¤ºäº† NeuroAI ç ”ç©¶ä¸­æ•°æ®å¤„ç†ç»†èŠ‚çš„é‡è¦æ€§ã€‚

### Phase 1: å·¥ç¨‹é€‚é…ä¸ç‰¹å¾å¯¹é½ (Engineering & Extraction)
* **æŒ‘æˆ˜:** LLaMA-3 çš„ Tokenizer æœºåˆ¶ä¸æ—§ç‰ˆæ¨¡å‹ä¸åŒï¼Œä¸” BF16 æ ¼å¼åœ¨éƒ¨åˆ†æ—§ç¯å¢ƒä¸­ä¸å…¼å®¹ã€‚
* **æ–¹æ¡ˆ:**
    * [cite_start]å®ç°äº† **Token-to-Word Merging**ï¼šå°† Subword Token çš„æ³¨æ„åŠ›/éšè—å±‚çŠ¶æ€åˆå¹¶ä¸ºå•è¯çº§ (Word-level) çŸ©é˜µï¼Œè§£å†³äº†åˆ†è¯ç²’åº¦ä¸åŒ¹é…é—®é¢˜ [cite: 420, 421]ã€‚
    * [cite_start]**Lower-Triangle Flattening:** åœ¨å¤„ç† Attention çŸ©é˜µæ—¶ï¼Œæå–ä¸‹ä¸‰è§’å¹¶å±•å¹³ï¼Œä¿ç•™äº†å‡ ä½•ç»“æ„ä¿¡æ¯ [cite: 454, 455]ã€‚
    * **BOS Fix:** ä¿®æ­£äº† LLaMA-3 ç‰¹æœ‰çš„ Begin-Of-Sentence æ ‡è®°å¯¼è‡´çš„å¯¹é½åç§»ã€‚

### Phase 2: æ—¶é—´å¯¹é½ç­–ç•¥çš„ä¿®æ­£ (Time Alignment Pivot)
* **è¯•é”™:** åˆæœŸå°è¯•å°†ç‰¹å¾å¯¹é½åˆ°æ¯ 2 ç§’ (TR) çš„ fMRI é‡‡é›†ç‚¹ã€‚
* **å¤±è´¥åŸå› :** åœ¨ç¼ºä¹é«˜ç²¾åº¦çœ¼åŠ¨æ•°æ® (Eye-tracking) çš„å¬åŠ›ä»»åŠ¡ä¸­ï¼ŒTR çº§çš„å¾®è§‚å¯¹é½è¢« HRF å»¶è¿Ÿå’Œå™ªå£°æ·¹æ²¡ï¼Œå¯¼è‡´ $r \approx 0$ã€‚
* [cite_start]**ä¿®æ­£:** è½¬å‘ **Sentence-Level Analysis**ã€‚å‚è€ƒè®ºæ–‡è¡¥å……ææ–™ï¼Œå°†â€œæ•´å¥è¯â€ä½œä¸ºä¸€ä¸ªåˆ†æå•ä½ï¼Œè®¡ç®—è¯¥æ—¶é—´æ®µå†…çš„ Mean BOLD ä¿¡å· [cite: 472, 473]ã€‚è¿™ä¸€æ”¹å˜å¤§å¹…æå‡äº†ä¿¡å™ªæ¯” (SNR)ï¼ŒæˆåŠŸæ•æ‰åˆ°äº†ç›¸å…³æ€§ä¿¡å·ã€‚

### Phase 3: è‡´å‘½çš„æ··æ·†å˜é‡ (The "Length" Confound) ğŸš¨
* **ç°è±¡:** åœ¨ä¸­æœŸæµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å‘ç° Layer 0 (Embedding) çš„é¢„æµ‹åˆ†æ•°å¼‚å¸¸é«˜ ($r \approx 0.30$)ï¼Œä¸”å…¨å±‚åˆ†æ•°å‘ˆç°å¹³ç›´çº¿ï¼Œæ— å±‚çº§å·®å¼‚ã€‚
* **è¯Šæ–­:** è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ **å¥å­é•¿åº¦æ•ˆåº” (Sentence Length Effect)**ã€‚
    * *ç”Ÿç†äº‹å®:* å¥å­è¶Šé•¿ $\rightarrow$ å¬è§‰çš®å±‚æ¿€æ´»è¶Šä¹… $\rightarrow$ BOLD ä¿¡å·è¶Šå¼ºã€‚
    * *æ¨¡å‹ç‰¹å¾:* å¥å­è¶Šé•¿ $\rightarrow$ å‘é‡ç´¯ç§¯èƒ½é‡/Attention éé›¶å…ƒç´ è¶Šå¤šã€‚
    * *ç»“è®º:* æ¨¡å‹å®é™…ä¸Šæ˜¯åœ¨â€œæ•°å•è¯ä¸ªæ•°â€æ¥é¢„æµ‹å¤§è„‘æ´»åŠ¨ï¼Œè€Œéåˆ©ç”¨è¯­ä¹‰ä¿¡æ¯ã€‚
* **æœ€ç»ˆæ–¹æ¡ˆ (De-confounding):** åœ¨å›å½’åˆ†æå‰å¼•å…¥æ§åˆ¶å˜é‡ã€‚
    1. è®¡ç®—æ¯å¥è¯çš„æ—¶é•¿ (Duration)ã€‚
    2. å¯¹ fMRI ä¿¡å·è¿›è¡Œ **æ®‹å·®å›å½’ (Residualization)**ï¼Œå‰”é™¤æ—¶é•¿å¯è§£é‡Šçš„éƒ¨åˆ†ã€‚
    3. ä½¿ç”¨æ®‹å·®åçš„ä¿¡å·è¿›è¡Œè®­ç»ƒã€‚
    * **ç»“æœ:** Layer 0 çš„åˆ†æ•°è¢«æœ‰æ•ˆæŠ‘åˆ¶ï¼Œä¸­é—´å±‚çš„è¯­ä¹‰ä¼˜åŠ¿ç»ˆäºæ˜¾éœ²å‡ºæ¥ï¼Œå‘ˆç°å‡ºç¬¦åˆé¢„æœŸçš„â€œå€’ U å‹â€æ›²çº¿ã€‚

---

## 4. å±€é™æ€§ (Limitations)

ä½œä¸ºä¸€ä¸ªâ€œæé™å¤ç°â€é¡¹ç›®ï¼Œæœ¬é¡¹ç›®å­˜åœ¨ä»¥ä¸‹å®¢è§‚å±€é™ï¼Œè¿™äº›ä¹Ÿæ˜¯æœªæ¥æ·±å…¥ç ”ç©¶çš„èµ·ç‚¹ï¼š
1.  [cite_start]**æ ·æœ¬é‡ (Sample Size):** ä»…ä½¿ç”¨äº†å•è¢«è¯• (`sub-EN057`) æ•°æ®ï¼Œç»“æœå¯èƒ½å—ä¸ªä½“å·®å¼‚å½±å“ [cite: 384]ã€‚
2.  [cite_start]**ç‰¹å¾ç²’åº¦:** åŸè®ºæ–‡ç»“åˆäº†çœ¼åŠ¨æ•°æ® (Eye-tracking) å’Œ Attention Matrices è¿›è¡Œç²¾ç»†åˆ†æ [cite: 452]ï¼Œæœ¬é¡¹ç›®ä¸»è¦ä¾èµ– Hidden States å’ŒéŸ³é¢‘æ—¶é—´æˆ³ã€‚
3.  [cite_start]**ç»Ÿè®¡æ•ˆåŠ›:** ç”±äºæ•°æ®é‡è¾ƒå°ï¼Œç›®å‰çš„ Base vs. Instruct å·®å¼‚åˆ†æå°šæœªé€šè¿‡å¤§è§„æ¨¡çš„ç½®æ¢æ£€éªŒ (Permutation Test) [cite: 483]ã€‚

---

## ğŸ‡¬ğŸ‡§ English Summary (Dev Log Included)

### Methodological Evolution & Challenges
This replication involved three critical iterations to align with the rigorous standards of Gao et al. (2025):

1.  [cite_start]**Feature Extraction Logic:** We implemented specific **Token-to-Word Merging** and **Lower-Triangle Flattening** to handle LLaMA-3's tokenizer and preserve the geometric structure of attention matrices[cite: 420, 454].
2.  **Time Alignment Pivot:** Initial attempts at TR-level (2s) alignment failed due to noise. We pivoted to **Sentence-Level Analysis** (Mean BOLD per sentence), which significantly improved the Signal-to-Noise Ratio (SNR) for the auditory task.
3.  **Solving the "Length Confound":**
    * *Issue:* Initial results showed suspiciously high performance at Layer 0 (Embedding) and a flat layer-wise trend.
    * *Diagnosis:* The model was predicting brain activity based on **Sentence Duration** (longer sentence = stronger BOLD = more feature energy), not semantics.
    * *Fix:* We implemented **Duration De-confounding** by regressing out sentence length from the fMRI signals before training. This successfully revealed the true semantic "Inverted-U" trend peaked at middle layers.

### Conclusion
This project successfully established a reproducible pipeline from **LLaMA-3.1 to fMRI**. [cite_start]While constrained by sample size, the results support the hypothesis that instruction tuning does not fundamentally alter the brain-like semantic representations in LLMs[cite: 12, 361].

---

### ğŸ“š References
1.  **Gao, C., et al. (2025).** *Increasing alignment of large language models with language processing in the human brain*. [cite_start]Nature Computational Science. [cite: 1, 4]
2.  **Li, J., et al. (2022).** *Le Petit Prince multilingual naturalistic fMRI corpus*. [cite_start]Scientific Data. [cite: 27]

---
*Created by [Your Name] | Dec 2025*
*Acknowledgement: Inspired by the work of Jixing Li, Ercong Nie, and Changjiang Gao.*
