# ğŸ§  Brain-Llama3.1-Encoding: A Preliminary Replication
## é€šè¿‡ LLaMA-3.1 ç¼–ç äººè„‘ fMRI ä¿¡å·

> **Base Paper:** Gao, C., Ma, Z., Chen, J. et al. Increasing alignment of large language models with language processing in the human brain. Nat Comput Sci 5, 1080â€“1090 (2025). https://doi.org/10.1038/s43588-025-00863-0

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäº **è®¡ç®—ç¥ç»è¯­è¨€å­¦ (Computational Neurolinguistics)** çš„å®è¯ç ”ç©¶ã€‚å— Gao et al. (2025) å‘è¡¨åœ¨ *Nature Computational Science* ä¸Šçš„å·¥ä½œå¯å‘ï¼Œæˆ‘åœ¨åŸºäº **Meta-LLaMA-3.1-8B (base & instruct)** æ„å»ºäº†ä¸€å¥—ç®€åŒ–çš„ç¥ç»ç¼–ç pipelineï¼Œå°è¯•éªŒè¯æ–‡ç« çš„ä¸€äº›åŸºæœ¬å‘ç°åœ¨Llama 3.1ä¸Šçš„æ•ˆæœã€‚

æœ¬é¡¹ç›®çš„æ ¸å¿ƒç›®æ ‡æ˜¯åœ¨æœ‰é™ç®—åŠ›ä¸‹ï¼Œå°è¯•éªŒè¯ **æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)** æ˜¯å¦æ˜¾è‘—æ”¹å˜äº†å¤§è¯­è¨€æ¨¡å‹åº•å±‚çš„è¯­ä¹‰è¡¨å¾åŠå…¶ä¸äººè„‘è¯­è¨€ç½‘ç»œçš„å¯¹é½åº¦ã€‚

---

## 1. æ ¸å¿ƒå‘ç°

é€šè¿‡å¯¹æ¯” **LLaMA-3.1-Base** ä¸ **LLaMA-3.1-Instruct** åœ¨ **Le Petit Prince (LPP)** fMRI æ•°æ®é›†ä¸Šçš„ç¼–ç æ€§èƒ½ï¼Œæˆ‘ä»¬å¾—å‡ºäº†ä»¥ä¸‹åˆæ­¥ç»“è®ºï¼š

### ğŸ“ˆ 1.1 ä¸­é—´å±‚æ•ˆåº” (The "Inverted-U" Trend)
æˆåŠŸå¤ç°äº†ç¥ç»è¯­è¨€å­¦é¢†åŸŸçš„ç»å…¸å‘ç°ï¼šæ¨¡å‹å¯¹å¤§è„‘çš„é¢„æµ‹èƒ½åŠ›å‘ˆç°â€œå€’Uå‹â€åˆ†å¸ƒã€‚
<img width="1000" height="600" alt="Code_Generated_Image (1)" src="https://github.com/user-attachments/assets/2dab9dd7-928d-4631-83fc-3756c6f9b425" />
* **Layer 0 (Embedding):** åœ¨å»é™¤äº†å¥å­é•¿åº¦æ··æ·†åï¼Œå…¶é¢„æµ‹èƒ½åŠ›æ˜¾è‘—ä½äºä¸­é—´å±‚ã€‚
* **Middle Layers (L16-L24):** **é¢„æµ‹èƒ½åŠ›è¾¾åˆ°å³°å€¼** (Max Pearson's $r \approx 0.60$, Top-5% $\approx 0.30$)ã€‚è¿™è¡¨æ˜ LLaMA çš„ä¸­é—´å±‚è¡¨å¾æœ€æ¥è¿‘äººç±»å¤§è„‘è¿›è¡Œå¥æ³•åˆ†æå’Œè¯­ä¹‰æ•´åˆçš„åŒºåŸŸã€‚
* **Late Layers:** éšç€æ¨¡å‹ä¸“æ³¨äº Next-token Predictionï¼Œå…¶ä¸å¤§è„‘é€šç”¨ç†è§£æœºåˆ¶çš„å¯¹é½åº¦ç•¥æœ‰ä¸‹é™ã€‚

<img width="4200" height="1800" alt="plot_B_heatmap" src="https://github.com/user-attachments/assets/718a3b92-a534-4533-9afb-ba2a231ee6a8" />
*(å›¾ï¼šBase æ¨¡å‹åœ¨ä¸åŒ Run ä¸Šçš„å±‚çº§æ€§èƒ½çƒ­åŠ›å›¾ï¼Œæ˜¾ç¤ºä¸­é—´å±‚çš„é«˜å“åº”åŒº)*

### 1.2 å¾®è°ƒçš„å½±å“
å®éªŒæ˜¾ç¤ºï¼ŒBase å’Œ Instruct ç‰ˆæœ¬çš„å±‚çº§å¯¹é½æ›²çº¿ **é«˜åº¦é‡å **ã€‚
* è¿™éªŒè¯äº† Gao et al. (2025) çš„ç»“è®ºï¼šæŒ‡ä»¤å¾®è°ƒ (RLHF/SFT) è™½ç„¶æå‡äº†ä»»åŠ¡è¡¨ç°ï¼Œä½†å¹¶æ²¡æœ‰æ˜¾è‘—å¢å¼ºæ¨¡å‹ä¸äººç±»å¤§è„‘æ´»åŠ¨çš„å¯¹é½ç¨‹åº¦ã€‚
* å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¤§å¤šæ•°å±‚çº§çš„ç‚¹è½åœ¨ $y=x$ çº¿é™„è¿‘ï¼Œè¡¨æ˜ä¸¤è€…åº•å±‚è¯­ä¹‰è¡¨å¾æœºåˆ¶åŸºæœ¬ä¸€è‡´ã€‚

<img width="2400" height="2400" alt="plot_C_scatter" src="https://github.com/user-attachments/assets/77da05c5-6b10-45be-bc13-8b8bab180979" />

<img width="3600" height="1800" alt="plot_A_difference (1)" src="https://github.com/user-attachments/assets/598ce0a4-9026-4bf9-b9c1-2aea3a5d0fcc" />

---

## 2. å®éªŒæ–¹æ³• 
### 2.1 æ•°æ®ä¸ç¯å¢ƒ
* **Dataset:** *Le Petit Prince* (LPP) fMRI Dataset (Sub-EN057, ~1.5h Audio) (å—ç®—åŠ›é™åˆ¶ï¼Œæˆ‘ä»¬åªéªŒè¯äº†ä¸€åè‹±æ–‡è¢«è¯•çš„å…¨ç¨‹fMRIæ•°æ®)ã€‚
* **Hardware:** AutoDL Cloud Server / **NVIDIA RTX 4090 (24GB VRAM)**.
* **Model Loading:** LLaMA-3.1-8B (BF16 / 4-bit Quantization via `bitsandbytes`).

### 2.2 æ ¸å¿ƒPipeline
1.  **ç‰¹å¾æå– (Feature Extraction):** æå– Layer 0-32 çš„ Hidden Statesï¼Œé‡‡ç”¨ **Sentence-level Mean Pooling** ä»¥é€‚åº”å¬åŠ›ä»»åŠ¡çš„ä½ä¿¡å™ªæ¯”ã€‚
2.  **è¡€æµåŠ¨åŠ›å­¦å»ºæ¨¡ (HRF Alignment):** ä½¿ç”¨ `nilearn` è¿›è¡Œ HRF å·ç§¯ï¼Œå¹¶åœ¨ 4s-10s èŒƒå›´å†…æœç´¢æœ€ä½³å»¶è¿Ÿ (Best Delay)ã€‚
3.  **é™ç»´ä¸å›å½’ (Encoding):** ä½¿ç”¨ PCA (n=15) é™ç»´ï¼Œé…åˆ Ridge Regression (5-Fold CV) è¿›è¡Œä½“ç´ çº§é¢„æµ‹ã€‚

---

## 3. æŒ‘æˆ˜ä¸æ–¹æ³•è®ºæ¼”è¿›

æœ¬é¡¹ç›®çš„å¤ç°å¹¶éä¸€å¸†é£é¡ºã€‚ä¸ºäº†é€¼è¿‘åŸè®ºæ–‡çš„é€»è¾‘ï¼Œæˆ‘ç»å†äº†ä¸‰æ¬¡å…³é”®çš„æ–¹æ³•è®ºè¿­ä»£ã€‚

### 1: å·¥ç¨‹é€‚é…ä¸ç‰¹å¾å¯¹é½
* **æŒ‘æˆ˜:** LLaMA-3 çš„ Tokenizer æœºåˆ¶ä¸æ—§ç‰ˆæ¨¡å‹ä¸åŒï¼Œä¸” BF16 æ ¼å¼åœ¨éƒ¨åˆ†æ—§ç¯å¢ƒä¸­ä¸å…¼å®¹ã€‚
* **æ–¹æ¡ˆ:**
    * å®ç°äº† **Token-to-Word Merging**ï¼šå°† Subword Token çš„æ³¨æ„åŠ›/éšè—å±‚çŠ¶æ€åˆå¹¶ä¸ºå•è¯çº§ (Word-level) çŸ©é˜µï¼Œè§£å†³äº†åˆ†è¯ç²’åº¦ä¸åŒ¹é…é—®é¢˜ã€‚
    * **Lower-Triangle Flattening:** åœ¨å¤„ç† Attention çŸ©é˜µæ—¶ï¼Œæå–ä¸‹ä¸‰è§’å¹¶å±•å¹³ï¼Œä¿ç•™äº†å‡ ä½•ç»“æ„ä¿¡æ¯ã€‚
    * **BOS Fix:** ä¿®æ­£äº† LLaMA-3 ç‰¹æœ‰çš„ Begin-Of-Sentence æ ‡è®°å¯¼è‡´çš„å¯¹é½åç§»ã€‚

### 2: æ—¶é—´å¯¹é½ç­–ç•¥çš„ä¿®æ­£
* **è¯•é”™:** åˆæœŸå°è¯•å°†ç‰¹å¾å¯¹é½åˆ°æ¯ 2 ç§’ (TR) çš„ fMRI é‡‡é›†ç‚¹ã€‚
* **å¤±è´¥åŸå› :** åœ¨ç¼ºä¹é«˜ç²¾åº¦çœ¼åŠ¨æ•°æ® (Eye-tracking) çš„å¬åŠ›ä»»åŠ¡ä¸­ï¼ŒTR çº§çš„å¾®è§‚å¯¹é½è¢« HRF å»¶è¿Ÿå’Œå™ªå£°æ·¹æ²¡ï¼Œå¯¼è‡´ $r \approx 0$ã€‚
* [cite_start]**ä¿®æ­£:** è½¬å‘ **Sentence-Level Analysis**ã€‚å‚è€ƒè®ºæ–‡è¡¥å……ææ–™ï¼Œå°†â€œæ•´å¥è¯â€ä½œä¸ºä¸€ä¸ªåˆ†æå•ä½ï¼Œè®¡ç®—è¯¥æ—¶é—´æ®µå†…çš„ Mean BOLD ä¿¡å· [cite: 472, 473]ã€‚è¿™ä¸€æ”¹å˜å¤§å¹…æå‡äº†ä¿¡å™ªæ¯” (SNR)ï¼ŒæˆåŠŸæ•æ‰åˆ°äº†ç›¸å…³æ€§ä¿¡å·ã€‚

### 3: æ··æ·†å˜é‡
* **ç°è±¡:** åœ¨ä¸­æœŸæµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å‘ç° Layer 0 (Embedding) çš„é¢„æµ‹åˆ†æ•°å¼‚å¸¸é«˜ ($r \approx 0.30$)ï¼Œä¸”å…¨å±‚åˆ†æ•°å‘ˆç°å¹³ç›´çº¿ï¼Œæ— å±‚çº§å·®å¼‚ã€‚
* **è¯Šæ–­:** è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ **å¥å­é•¿åº¦æ•ˆåº” (Sentence Length Effect)**ã€‚
    * *ç”Ÿç†äº‹å®:* å¥å­è¶Šé•¿ $\rightarrow$ å¬è§‰çš®å±‚æ¿€æ´»è¶Šä¹… $\rightarrow$ BOLD ä¿¡å·è¶Šå¼ºã€‚
    * *æ¨¡å‹ç‰¹å¾:* å¥å­è¶Šé•¿ $\rightarrow$ å‘é‡ç´¯ç§¯èƒ½é‡/Attention éé›¶å…ƒç´ è¶Šå¤šã€‚
    * *ç»“è®º:* æ¨¡å‹å®é™…ä¸Šæ˜¯åœ¨â€œæ•°å•è¯ä¸ªæ•°â€æ¥é¢„æµ‹å¤§è„‘æ´»åŠ¨ï¼Œè€Œéåˆ©ç”¨è¯­ä¹‰ä¿¡æ¯ã€‚
* **æœ€ç»ˆæ–¹æ¡ˆ (De-confounding):** åœ¨å›å½’åˆ†æå‰å¼•å…¥æ§åˆ¶å˜é‡ã€‚
    1. è®¡ç®—æ¯å¥è¯çš„æ—¶é•¿ (Duration)ã€‚
    2. å¯¹ fMRI ä¿¡å·è¿›è¡Œ **æ®‹å·®å›å½’ (Residualization)**ï¼Œå‰”é™¤æ—¶é•¿å¯è§£é‡Šçš„éƒ¨åˆ†ã€‚
    3. ä½¿ç”¨æ®‹å·®åçš„ä¿¡å·è¿›è¡Œè®­ç»ƒã€‚
    * **ç»“æœ:** Layer 0 çš„åˆ†æ•°è¢«æœ‰æ•ˆæŠ‘åˆ¶ï¼Œä¸­é—´å±‚çš„è¯­ä¹‰ä¼˜åŠ¿ç»ˆäºæ˜¾éœ²å‡ºæ¥ï¼Œå‘ˆç°å‡ºç¬¦åˆé¢„æœŸçš„â€œå€’ U å‹â€æ›²çº¿ã€‚

---

## 4. å±€é™æ€§

ä½œä¸ºä¸€ä¸ªæœ‰é™æ¡ä»¶ä¸‹çš„ç®€æ˜“å¤ç°é¡¹ç›®ï¼Œæœ¬é¡¹ç›®å­˜åœ¨ä»¥ä¸‹å®¢è§‚å±€é™ï¼š
1.  **æ ·æœ¬é‡:** ä»…ä½¿ç”¨äº†å•è¢«è¯• (`sub-EN057`) æ•°æ®ï¼Œç»“æœå¯èƒ½å—ä¸ªä½“å·®å¼‚å½±å“ ã€‚
2.  **ç‰¹å¾ç²’åº¦:** åŸè®ºæ–‡ç»“åˆäº†çœ¼åŠ¨æ•°æ® (Eye-tracking) å’Œ Attention Matrices è¿›è¡Œç²¾ç»†åˆ†æï¼Œæœ¬é¡¹ç›®ä¸»è¦ä¾èµ– Hidden States å’ŒéŸ³é¢‘æ—¶é—´æˆ³ã€‚
3.  **ç»Ÿè®¡æ•ˆåŠ›:** ç”±äºæ•°æ®é‡è¾ƒå°ï¼Œç›®å‰çš„ Base vs. Instruct å·®å¼‚åˆ†æå°šæœªé€šè¿‡å¤§è§„æ¨¡çš„ç½®æ¢æ£€éªŒã€‚

---

## ğŸ‡¬ğŸ‡§ English Summary (Dev Log Included)

### Methodological Evolution & Challenges
This replication involved three critical iterations to align with the rigorous standards of Gao et al. (2025):

1.  [cite_start]**Feature Extraction Logic:** We implemented specific **Token-to-Word Merging** and **Lower-Triangle Flattening** to handle LLaMA-3's tokenizer and preserve the geometric structure of attention matrices[cite: 420, 454].
2.  **Time Alignment Pivot:** Initial attempts at TR-level (2s) alignment failed due to noise. We pivoted to **Sentence-Level Analysis** (Mean BOLD per sentence), which significantly improved the Signal-to-Noise Ratio (SNR) for the auditory task.
3.  **Solving the "Length Confound":**
    * *Issue:* Initial results showed suspiciously high performance at Layer 0 (Embedding) and a flat layer-wise trend.
    * *Diagnosis:* The model was predicting brain activity based on **Sentence Duration** (longer sentence = stronger BOLD = more feature energy), not semantics.
    * *Fix:* We implemented **Duration De-confounding** by regressing out sentence length from the fMRI signals before training. This successfully revealed the true semantic "Inverted-U" trend peaked at middle layers.

### Conclusion
This project successfully established a reproducible pipeline from **LLaMA-3.1 to fMRI**. [cite_start]While constrained by sample size, the results support the hypothesis that instruction tuning does not fundamentally alter the brain-like semantic representations in LLMs[cite: 12, 361].

---

### References
1.  Gao, C., Ma, Z., Chen, J. et al. Increasing alignment of large language models with language processing in the human brain. Nat Comput Sci 5, 1080â€“1090 (2025). https://doi.org/10.1038/s43588-025-00863-0
2.  Li, J., Bhattasali, S., Zhang, S. et al. Le Petit Prince multilingual naturalistic fMRI corpus. Sci Data 9, 530 (2022). https://doi.org/10.1038/s41597-022-01625-7

---
*Created by Haoyang Chai | Dec 2025*
